{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc17ee6-f359-493c-be35-68a3b89b19d1",
   "metadata": {},
   "source": [
    "stemming and lematization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed9ab1-eea0-4398-b320-79122ddd8ee9",
   "metadata": {},
   "source": [
    "stemming reduces terms to their roots or stems.\n",
    "rules or stemming are\n",
    "all those words having ational reduces to ate like relational to relate\n",
    "all those words having sses reduces to ss like grasses to grass\n",
    "all those words having ing reduces to root word like enjoying to enjoy\n",
    "Porter Stemmer is the most commonly used stemming algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cdd78e8-77ed-4db6-9cf3-42cfb204ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "#important libraries for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956a1e2b-0492-4ed0-9040-e73d804ec8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Stemming is a fundamental technique in Natural Language Processing (NLP) used to reduce words to their root or base form, aiming to normalize text for analysis. For instance, applying stemming to the words \"running\", \"runs\", and \"runner\" would result in the root \"run\". This process helps in condensing variations of words to a common form, which is crucial for tasks like text classification, information retrieval, and sentiment analysis. Despite its simplicity, stemming algorithms like Porter and Snowball can sometimes produce stems that are not actual words, which may affect accuracy in certain contexts. Nevertheless, stemming remains a valuable preprocessing step in many NLP applications, contributing to the efficiency and effectiveness of text processing pipelines.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1031ab-2116-49b0-be29-5e0fe55cde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    sentence = nltk.sent_tokenize(text)\n",
    "    stemer = PorterStemmer()\n",
    "    for i in range(len(sentence)):\n",
    "        # Selecting only the alphabetic words\n",
    "        words = re.sub('[^a-zA-Z]', ' ', sentence[i])\n",
    "        # lowering words\n",
    "        words = words.lower()\n",
    "        # splitting into words\n",
    "        words = words.split()\n",
    "        temp = []\n",
    "        for word in words:\n",
    "            # condition to check only those words that are not in stopwords\n",
    "            if word not in stopwords.words('english'):\n",
    "                # applying stemming\n",
    "                stem = stemer.stem(word)\n",
    "                temp.append(stem)\n",
    "        \n",
    "        sentence[i]= ' '.join(temp)\n",
    "    \n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73598b19-c2d2-440f-9c3f-3738c6724c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed paragraph:\n",
      "['stem fundament techniqu natur languag process nlp use reduc word root base form aim normal text analysi', 'instanc appli stem word run run runner would result root run', 'process help condens variat word common form crucial task like text classif inform retriev sentiment analysi', 'despit simplic stem algorithm like porter snowbal sometim produc stem actual word may affect accuraci certain context', 'nevertheless stem remain valuabl preprocess step mani nlp applic contribut effici effect text process pipelin']\n"
     ]
    }
   ],
   "source": [
    "print(\"stemmed paragraph:\")\n",
    "print(stemmer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c34ca-7c48-400e-af75-c06ed28e3d42",
   "metadata": {},
   "source": [
    "lematization\n",
    "it reduces the words to their grammatical root unlike stemming which reduces the words to any of the root without consedring grammetical roots\n",
    "like lematize of flies is fly but stemming is fli\n",
    "so lematization reduces the flies to its grammatical root fly while stemming reduces to fli only removes es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d2624a0-d23c-4e44-a98a-2d5b753ceafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    sentence=nltk.sent_tokenize(text)\n",
    "    lematize=WordNetLemmatizer()\n",
    "    for i in range(len(sentence)):\n",
    "        words=re.sub('[^a-zA-Z]',' ',sentence[i])\n",
    "        words=words.lower()\n",
    "        words=words.split()\n",
    "        temp=[]\n",
    "        for word in words:\n",
    "            if word not in stopwords.words('english'):\n",
    "                lem=lematize.lemmatize(word)\n",
    "                temp.append(lem)\n",
    "            sentence[i]=' '.join(temp)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87437725-b4ab-40c0-941d-a274586195c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Lemmatization is a crucial technique in Natural Language Processing (NLP) that aims to transform words into their base or dictionary form, known as the lemma. Unlike stemming, which simply chops off prefixes and suffixes to produce a root form that may not always be a valid word, lemmatization considers the context and grammatical structure of words to ensure accuracy. This process involves mapping words back to their canonical forms based on linguistic rules and dictionaries, thereby enhancing the quality and interpretability of textual analysis. For example, lemmatization would correctly reduce \"running\" to \"run\", \"better\" to \"good\", and \"mice\" to \"mouse\", making it indispensable in tasks like text classification, sentiment analysis, and machine translation. Despite being computationally more intensive than stemming, lemmatization provides more meaningful insights by preserving the semantic meaning of words, which is essential for extracting precise information from text data.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3bacc65-6105-487b-8c93-fe37bf320abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lemmatization crucial technique natural language processing nlp aim transform word base dictionary form known lemma',\n",
       " 'unlike stemming simply chop prefix suffix produce root form may always valid word lemmatization considers context grammatical structure word ensure accuracy',\n",
       " 'process involves mapping word back canonical form based linguistic rule dictionary thereby enhancing quality interpretability textual analysis',\n",
       " 'example lemmatization would correctly reduce running run better good mouse mouse making indispensable task like text classification sentiment analysis machine translation',\n",
       " 'despite computationally intensive stemming lemmatization provides meaningful insight preserving semantic meaning word essential extracting precise information text data']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c53c41-0c0c-421d-99e3-143e4f74cb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english stopwords:\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"english stopwords:\")\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e003d5a-7ab0-48f1-876b-c7434d2f747c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
