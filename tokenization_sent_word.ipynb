{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5458075d-5253-4741-8cf7-b9bddcfa5461",
   "metadata": {},
   "source": [
    "practicing tokenization\n",
    "tokenization is the splitting of sentence into chunks of words.\n",
    "there are two type of tokenization word tokenization and sentence tokenization\n",
    "word tokenization tokenize sentence into single words\n",
    "sentence tokenization tokenize paragraph into single sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc418a04-576c-47ea-9d0a-817e21b312dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries are\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02ccff4-1460-4a4e-9318-7b8a941aa13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Natural language processing (NLP) is a fascinating field that deals with the interaction between computers and humans through natural language. It encompasses a wide range of tasks, from simple tasks like tokenization and stemming to more complex tasks such as sentiment analysis and machine translation. Tokenization, in particular, plays a foundational role in NLP by breaking down text into smaller units called tokens.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1cadf0-cea7-4b73-ba4e-827eb0d7b77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence tokenization\n",
      "['natural', 'language', 'processing', '(nlp)', 'is', 'a', 'fascinating', 'field', 'that', 'deals', 'with', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language.'] \n",
      "\n",
      "['it', 'encompasses', 'a', 'wide', 'range', 'of', 'tasks,', 'from', 'simple', 'tasks', 'like', 'tokenization', 'and', 'stemming', 'to', 'more', 'complex', 'tasks', 'such', 'as', 'sentiment', 'analysis', 'and', 'machine', 'translation.'] \n",
      "\n",
      "['tokenization,', 'in', 'particular,', 'plays', 'a', 'foundational', 'role', 'in', 'nlp', 'by', 'breaking', 'down', 'text', 'into', 'smaller', 'units', 'called', 'tokens.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence=nltk.sent_tokenize(text)\n",
    "print(\"sentence tokenization\")\n",
    "for i in range(len(sentence)):\n",
    "    words=sentence[i]\n",
    "    words=words.lower()\n",
    "    words=words.split()\n",
    "    print(words,\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e289efb3-760f-49cf-b801-da84edef5797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word tokenization of sentence is \n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'that', 'deals', 'with', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.', 'It', 'encompasses', 'a', 'wide', 'range', 'of', 'tasks', ',', 'from', 'simple', 'tasks', 'like', 'tokenization', 'and', 'stemming', 'to', 'more', 'complex', 'tasks', 'such', 'as', 'sentiment', 'analysis', 'and', 'machine', 'translation', '.', 'Tokenization', ',', 'in', 'particular', ',', 'plays', 'a', 'foundational', 'role', 'in', 'NLP', 'by', 'breaking', 'down', 'text', 'into', 'smaller', 'units', 'called', 'tokens', '.']\n"
     ]
    }
   ],
   "source": [
    "word=nltk.word_tokenize(text)\n",
    "print(\"word tokenization of sentence is \")\n",
    "print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
